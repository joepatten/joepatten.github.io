---
layout: page
title: Monte Carlo Model
sidebar_link: false
permalink: /blog/rlcs_model
---

<strong>Description</strong> <p style='font-size:10 px;'>The forecasts above are based on 1,000 simulations for each game. I use Markov chain to simulate the events of each team and their opponent. Events could include shots, saves, passes, etc. I house the transition probabilities in a transition matrix. A transition probability is defined as the probability of an event occurring given a certain event has just occurred. For example, one transition probability would be the probability of team B saving the ball when team A shoots the ball. Transition matrices are constructed using play-by-play data from previous weeks. The model is rather simplistic and does not take into account things like momentum (which is an important factor to consider in Rocket League). Future work will take this into account as well as explore how similar certain teams are with the hope of increasing the accuracy of my forecasts. Predictions should become more accurate as the season goes on, thus we should get a more accurate picture of how teams behave. Future work will also include using priors to forecast games when there is little data about one or both of the teams. I also plan on evaluating my predictions in order to calibrate or even rework my model.

<br>
<br>

Lastly, I plan on ranking each team from NA and EU, giving them an SPI score, and offensive score, and a defensive score. I am not sure when I will get to all of this (as I am currently working and finishing up grad school) so don't hold your breath. Thanks for visiting!</p>

Clich <a href=" /blog/rlcs_predictions_eval">here</a> to see how this model performs.







What good are predictions if we don't know how well our model performs? Anyone could come up with a model or algorithm that spit out probabilities, but not all predictions will be that accurate. So the next question is: how should we measure the accuracy of our model? One might think of finding the average number of matches I accurately predicted (where any event probability above .5 would be treated as a 1, and any event probability below .5 would be treated as a 0. Using this somewhat naive approach, I get an "accuracy" score of above 70%. However, this does not take into account the magnitude of the probabilities (for example, 52% chance of an event happening should not be treated the same way as a 74% chance of an event happening). It would be nice to keep this magnitude issue in mind when evaluating the model.

One way to address this issue is to bin the predictions I calculated using the model, and then compare them with the actual scores that have been realized. The following plot shows this:


<img src="../../assets/blog/rlcs/actual_versus_forecast.png" alt="predicted versus real accuracy">

My (binned) predictions looks promising. The closer the forecasted chance of winning to 50%,  we see that the actual win percentage is fairly close to the forecasted chance of winning. I do want to note that I have only used the model on 1 partial season of RLCS. Thus, we will get a clearer picture at how "accurate" my model is once I have added more data to test the model. Another thing we can do is use a (modified) Brier Test. This will show us how much better (or worse) my model performs when compared with a baseline model. The higher the score, the better. The baseline model usually used is giving a 50% chance of an event occurring for every event or state. The following table shows how well our forecasts perform when compared to forecasts from fivethirtyeight.com of other sports:



<table border="1">
<tr><td><strong>Forecasting Score</strong></td><td> <strong>Sport</strong></td></tr>
<tr><td>.0311</td><td> MLB</td></tr>
<tr><td>.0696</td><td> Club Soccer Matches</td></tr>
<tr><td>.0962</td><td> NFL</td></tr>
<tr><td>.1296</td><td> NBA</td></tr>
<tr><td>.1917</td><td> World Cup (men)</td></tr>
<tr><td><font color="red">.2035</font></td><td><font color="red"> My RLCS Forecasts</font></td></tr>
<tr><td>.2502</td><td> Tennis (women)</td></tr>
<tr><td>.2715</td><td> World Cup (women)</td></tr>
<tr><td>.3135</td><td> NFL Playoffs</td></tr>
<tr><td>.3228</td><td> March Madness (men)</td></tr>
<tr><td>.3244</td><td> Tennis (men)</td></tr>
<tr><td>.3604</td><td> NBA Playoffs</td></tr>
<tr><td>.4568</td><td> Club Soccer League</td></tr>
<tr><td>.4806</td><td> MLB Playoffs</td></tr>
<tr><td>.5232</td><td> March Madness (women)</td></tr>
</table>

